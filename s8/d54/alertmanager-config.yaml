apiVersion: v1
kind: Secret
metadata:
  name: alertmanager-kube-prometheus-alertmanager
  namespace: monitoring
type: Opaque
stringData:
  alertmanager.yaml: |
    global:
      slack_api_url: 'WEBHOOKK'  # üîÑ Cambiar por tu webhook
      resolve_timeout: 5m

    # Template para mensajes m√°s informativos
    templates:
    - '/etc/alertmanager/templates/*.tmpl'

    route:
      group_by: ['alertname', 'team']
      group_wait: 10s
      group_interval: 10s
      repeat_interval: 12h
      receiver: 'default-receiver'
      
      routes:
      # Critical alerts -> Inmediato + escalation
      - match:
          severity: critical
        receiver: 'critical-alerts'
        group_wait: 0s
        repeat_interval: 5m
        
      # Warning alerts -> Slack normal
      - match:
          severity: warning
        receiver: 'warning-alerts'
        group_wait: 2m
        repeat_interval: 1h
        
      # Info alerts -> Solo durante horario laboral
      - match:
          severity: info
        receiver: 'info-alerts'
        active_time_intervals:
        - business-hours

    # Time intervals
    time_intervals:
    - name: business-hours
      time_intervals:
      - times:
        - start_time: '09:00'
          end_time: '18:00'
        weekdays: ['monday:friday']

    receivers:
    - name: 'default-receiver'
      slack_configs:
      - channel: '#devops-alerts'
        title: 'üîî {{ .GroupLabels.alertname }}'
        text: |
          {{ range .Alerts }}
          *Alert:* {{ .Annotations.summary }}
          *Details:* {{ .Annotations.description }}
          *Severity:* {{ .Labels.severity }}
          {{ end }}

    - name: 'critical-alerts'
      slack_configs:
      - channel: '#incidents'
        title: 'üö® CRITICAL ALERT üö®'
        text: |
          @channel IMMEDIATE ATTENTION REQUIRED
          
          {{ range .Alerts }}
          *Alert:* {{ .Annotations.summary }}
          *Description:* {{ .Annotations.description }}
          *Runbook:* {{ .Labels.runbook }}
          *Team:* {{ .Labels.team }}
          {{ end }}
        color: 'danger'
        
      # # Tambi√©n enviar por email para critical
      # email_configs:
      # - to: 'oncall@company.com'
      #   subject: 'üö® CRITICAL: {{ .GroupLabels.alertname }}'
      #   body: |
      #     CRITICAL alert fired:
      #     {{ range .Alerts }}
      #     {{ .Annotations.description }}
      #     {{ end }}

    - name: 'warning-alerts'
      slack_configs:
      - channel: '#monitoring'
        title: '‚ö†Ô∏è Warning Alert'
        text: |
          {{ range .Alerts }}
          *Alert:* {{ .Annotations.summary }}
          *Details:* {{ .Annotations.description }}
          {{ end }}
        color: 'warning'

    - name: 'info-alerts'
      slack_configs:
      - channel: '#monitoring-info'
        title: 'üìä Info Alert'
        text: |
          {{ range .Alerts }}
          {{ .Annotations.summary }}
          {{ end }}
        color: 'good'

    # Inhibition rules - No alertar cosas redundantes
    inhibit_rules:
    - source_match:
        severity: 'critical'
      target_match:
        severity: 'warning'
      equal: ['alertname', 'namespace', 'pod']
      
    - source_match:
        alertname: 'SLOErrorBudgetBurnRateCritical'
      target_match:
        alertname: 'SLOErrorBudgetBurnRateHigh'
      equal: ['service']